# Yemek FotoÄŸrafÄ±ndan Besin DeÄŸeri Tahmini ve YorumlanmasÄ±

**Pupilica AI Hackathon iÃ§in geliÅŸtirilmiÅŸtir.**

Bu proje, tek bir yemek fotoÄŸrafÄ±ndan yola Ã§Ä±karak yemeÄŸin **aÄŸÄ±rlÄ±k (gram), kalori, yaÄŸ, karbonhidrat ve protein** deÄŸerlerini tahmin eden bir derin Ã¶ÄŸrenme modelidir. Modelin yaptÄ±ÄŸÄ± bu sayÄ±sal tahminler, Google'Ä±n gÃ¼Ã§lÃ¼ dil modeli **Gemini 2.5 Flash**'a gÃ¶nderilerek kullanÄ±cÄ± iÃ§in anlamlÄ± ve yorumlanmÄ±ÅŸ bir Ã§Ä±ktÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. KullanÄ±cÄ±lar ayrÄ±ca, tahmin edilen besin deÄŸerleri hakkÄ±nda Gemini'ye interaktif olarak sorular sorabilirler.

## ğŸš€ Uygulama

Projenin canlÄ± demosuna aÅŸaÄŸÄ±daki adresten ulaÅŸabilirsiniz:
**[nutritionassistant.streamlit.app](http://nutritionassistant.streamlit.app)**

## Model Checkpoint
 Modelin `state_dict` dosyasÄ±na Hugging Face Ã¼zerinden ulaÅŸabilirsiniz:  
ğŸ‘‰ [theycallmeburki/siglip2_regressor](https://huggingface.co/theycallmeburki/siglip2_regressor)
- **HatÄ±rlatma**: Kullanabilmek iÃ§in Ã¶nce model class'Ä± tanÄ±mlanmalÄ± ! 

## ğŸ› ï¸ Teknik Detaylar

### Model Mimarisi

Bu projede, temel olarak Google tarafÄ±ndan geliÅŸtirilen **Siglip2** vision encoder modeli kullanÄ±lmÄ±ÅŸtÄ±r.

-   **Transfer Learning YaklaÅŸÄ±mÄ±:** Siglip2 gibi devasa bir modeli elimizdeki 4783 fotoÄŸraflÄ±k veri setiyle baÅŸtan sona eÄŸitmek hem hesaplama maliyeti yÃ¼ksek hem de overfitting riski taÅŸÄ±yan bir sÃ¼reÃ§tir. Bu nedenle, modelin Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ± dondurulmuÅŸ ve sadece son katmanda bulunan **2 katmanlÄ± MLP (Multi-Layer Perceptron)** ve modele Ã¶zel olarak eklenen **regresyon baÅŸlÄ±ÄŸÄ± (regression head)** eÄŸitilmiÅŸtir.
-   **Regresyon BaÅŸlÄ±ÄŸÄ± (Regression Head):** Modelin gÃ¶rsel Ã¶zelliklerden sayÄ±sal besin deÄŸerlerini tahmin etmesini saÄŸlayan katman aÅŸaÄŸÄ±daki gibi tasarlanmÄ±ÅŸtÄ±r:

```python
self.reg_head = nn.Sequential(
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(hidden_size, output_dim) # output_dim = 5 (aÄŸÄ±rlÄ±k, kalori, yaÄŸ, karb, protein)
)
```

Bu yaklaÅŸÄ±m, bÃ¼yÃ¼k bir modelin gÃ¼Ã§lÃ¼ gÃ¶rsel anlama yeteneÄŸinden faydalanÄ±rken, kendi Ã¶zel gÃ¶revimiz iÃ§in modeli hÄ±zlÄ± ve verimli bir ÅŸekilde adapte etmemizi saÄŸlamÄ±ÅŸtÄ±r.

### EÄŸitim DetaylarÄ±

Modelin eÄŸitimi sÄ±rasÄ±nda aÅŸaÄŸÄ±daki optimizasyon ve Ã¶ÄŸrenme oranÄ± stratejileri kullanÄ±lmÄ±ÅŸtÄ±r:

-   **Loss Fonksiyonu:** Modelin tahminleri ile gerÃ§ek deÄŸerler arasÄ±ndaki hatayÄ± Ã¶lÃ§mek iÃ§in `L1Loss` (Mean Absolute Error) kullanÄ±lmÄ±ÅŸtÄ±r.
    ```python
    loss_fn = nn.L1Loss()
    ```
-   **Optimizer:** AÄŸÄ±rlÄ±klarÄ±n gÃ¼ncellenmesi iÃ§in `AdamW` optimizer tercih edilmiÅŸtir. Bu optimizer, standart Adam'a gÃ¶re aÄŸÄ±rlÄ±k bozunmasÄ±nÄ± (weight decay) daha etkili bir ÅŸekilde uygular.
    ```python
    optimizer = torch.optim.AdamW(params=model.parameters(), lr=5e-5)
    ```
-   **Ã–ÄŸrenme OranÄ± ZamanlayÄ±cÄ±sÄ± (Scheduler):** EÄŸitim boyunca Ã¶ÄŸrenme oranÄ±nÄ± dinamik olarak ayarlamak iÃ§in `OneCycleLR` stratejisi kullanÄ±lmÄ±ÅŸtÄ±r. Bu strateji, eÄŸitim baÅŸlangÄ±cÄ±nda Ã¶ÄŸrenme oranÄ±nÄ± yavaÅŸÃ§a artÄ±rÄ±r, maksimum bir deÄŸere ulaÅŸtÄ±rÄ±r ve ardÄ±ndan eÄŸitimin sonuna doÄŸru kademeli olarak azaltÄ±r. Bu, modelin daha hÄ±zlÄ± ve daha kararlÄ± bir ÅŸekilde yakÄ±nsamasÄ±na yardÄ±mcÄ± olur.
    ```python
    scheduler = OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=len(train_loader), epochs=NUM_EPOCHS, div_factor=20.0)
    ```

### Veri Seti (Dataset)

-   **Kaynak:** Projede **Nutrition5k** veri seti kullanÄ±lmÄ±ÅŸtÄ±r.
-   **Veri SeÃ§imi:** Veri setinin `side_angled_images` klasÃ¶rÃ¼nden, her bir yemek iÃ§in farklÄ± aÃ§Ä±lardan Ã§ekilmiÅŸ fotoÄŸraflar arasÄ±ndan rastgele sadece bir tanesi seÃ§ilerek toplam **4793** resimlik bir veri havuzu oluÅŸturulmuÅŸtur.
-   **Veri TemizliÄŸi (Data Cleaning):** Veri seti incelendiÄŸinde, yaklaÅŸÄ±k 10 adet gÃ¶rsel iÃ§in `8000 gram` gibi absÃ¼rt ve hatalÄ± deÄŸerler girildiÄŸi tespit edilmiÅŸtir. Regresyon gÃ¶revlerinde bu tÃ¼r aykÄ±rÄ± deÄŸerler (outliers), modelin performansÄ±nÄ± ciddi ÅŸekilde dÃ¼ÅŸÃ¼rebilir ve metriklerin yanlÄ±ÅŸ yorumlanmasÄ±na neden olabilir. Bu nedenle, hatalÄ± olduÄŸu doÄŸrulanan bu veriler eÄŸitim setinden Ã§Ä±karÄ±larak modelin daha stabil ve doÄŸru Ã¶ÄŸrenmesi saÄŸlanmÄ±ÅŸtÄ±r.

## ğŸ“Š EÄŸitim SÃ¼reci ve SonuÃ§lar

Model, early stopping mekanizmasÄ± devreye girerek eÄŸitilmiÅŸ ve en iyi doÄŸrulama performansÄ±nÄ± gÃ¶sterdiÄŸi 16. epochâ€™ta kaydedilmiÅŸtir. EÄŸitim sonunda elde edilen metrikler aÅŸaÄŸÄ±daki gibidir.

**Not:** VektÃ¶r olarak verilen metrikler sÄ±rasÄ±yla `[AÄŸÄ±rlÄ±k, Kalori, YaÄŸ, Karbonhidrat, Protein]` deÄŸerlerine karÅŸÄ±lÄ±k gelmektedir.

### Metrik Tablosu (Epoch: 16)

| Metrik     | Train DeÄŸerleri                         | Validation DeÄŸerleri                    |
| :--------- | :-------------------------------------- | :-------------------------------------- |
| **Loss** | 0.2428                                  | 0.3025                                  |
| **RÂ² Score** | `[0.89, 0.88, 0.83, 0.82, 0.86]`        | `[0.83, 0.75, 0.65, 0.71, 0.71]`        |
| **RMSE** | `[0.33, 0.35, 0.41, 0.42, 0.39]`        | `[0.42, 0.48, 0.57, 0.55, 0.52]`        |
| **MAPE** | 8.09%                                   | 9.10%                                   |
| **MAE** | `[0.23, 0.23, 0.25, 0.28, 0.23]`        | `[0.27, 0.30, 0.33, 0.35, 0.28]`        |
| **MSE** | `[0.11, 0.12, 0.17, 0.18, 0.15]`        | `[0.17, 0.23, 0.33, 0.30, 0.27]`        |
| **LR** | 0.000998                                | -                                       |


### Metrik Grafikleri

<table>
<tr>
  <td><img src="graphs/r2.png" alt="R2" width="400"/></td>
  <td><img src="graphs/loss.png" alt="Loss" width="400"/></td>
</tr>
<tr>
  <td><img src="graphs/rmse.png" alt="RMSE" width="400"/></td>
  <td><img src="graphs/mae.png" alt="MAE" width="400"/></td>
</tr>
<tr>
  <td><img src="graphs/mape.png" alt="MAPE" width="400"/></td>
  <td><img src="graphs/mse.png" alt="MSE" width="400"/></td>
</tr>
</table>


---

**Proje Burak Ã–zdemir tarafÄ±ndan geliÅŸtirilmiÅŸtir. SorularÄ±nÄ±z iÃ§in: ozdemrburak@yahoo.com adresinden ulaÅŸabilirsiniz.**
