import streamlit as st
import google.generativeai as genai
from PIL import Image
from get_prediction import predict_image

# Configure page
st.set_page_config(
    page_title="Nutrition Assistant",
    page_icon="ğŸ",
    layout="wide"
)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'current_analysis' not in st.session_state:
    st.session_state.current_analysis = None
if 'ai_response' not in st.session_state:
    st.session_state.ai_response = None

# Title and description
st.title("ğŸ Beslenme AsistanÄ± Chatbot")
st.markdown("Yiyecek fotoÄŸrafÄ±nÄ±zÄ± analiz edin ve beslenme hakkÄ±nda soru sorun!")

# Sidebar for API configuration
with st.sidebar:
    st.header("âš™ï¸ YapÄ±landÄ±rma")
    gemini_api_key = st.text_input(
        "Gemini API AnahtarÄ±",
        type="password",
        help="Google Gemini API anahtarÄ±nÄ±zÄ± girin"
    )

    if gemini_api_key:
        genai.configure(api_key=gemini_api_key)
        st.success("âœ… API anahtarÄ± yapÄ±landÄ±rÄ±ldÄ±!")

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
        st.session_state.chat_history = []
        st.session_state.current_analysis = None
        st.session_state.ai_response = None
        st.rerun()

# Main content
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“¸ FotoÄŸraf YÃ¼kle")
    uploaded_file = st.file_uploader(
        "Bir yiyecek fotoÄŸrafÄ± seÃ§in...",
        type=['png', 'jpg', 'jpeg'],
        help="Beslenme iÃ§eriÄŸini analiz etmek iÃ§in bir yiyecek fotoÄŸrafÄ± yÃ¼kleyin"
    )

    if uploaded_file is not None:
        # Display uploaded image
        image = Image.open(uploaded_file)
        st.image(image, caption="YÃ¼klenen FotoÄŸraf", use_column_width=50)

        if gemini_api_key:
            try:
                with st.spinner("FotoÄŸraf analiz ediliyor..."):
                    # Process image with SigLIP2 regressor - Fixed variable order
                    weight, cal, fat, carb, protein = predict_image(uploaded_file).squeeze().tolist()

                # Store analysis results
                st.session_state.current_analysis = {
                    'weight': weight,
                    'calories': cal,
                    'carbs': carb,
                    'fat': fat,
                    'protein': protein,
                    'image': uploaded_file
                }

                # Display raw predictions
                st.subheader("ğŸ”¢ Tespit Edilen DeÄŸerler")
                metrics_col1, metrics_col2 = st.columns(2)

                with metrics_col1:
                    st.metric("AÄŸÄ±rlÄ±k", f"{weight:.1f}g")
                    st.metric("Kalori", f"{cal:.0f} kcal")
                    st.metric("Karbonhidrat", f"{carb:.1f}g")

                with metrics_col2:
                    st.metric("YaÄŸ", f"{fat:.1f}g")
                    st.metric("Protein", f"{protein:.1f}g")

                # Initial analysis if not done yet
                prediction_key = f"{uploaded_file.name}_{weight:.1f}_{cal:.0f}_{carb:.1f}_{fat:.1f}_{protein:.1f}"

                if 'last_prediction_key' not in st.session_state or st.session_state.get(
                        'last_prediction_key') != prediction_key:
                    with st.spinner("Ä°lk analiz yapÄ±lÄ±yor..."):
                        try:
                            model = genai.GenerativeModel('gemini-2.5-flash')
                            image_pil = Image.open(uploaded_file)

                            initial_prompt = f"""
                            Bu fotoÄŸraftaki yiyeceÄŸi tanÄ±mla ve beslenme deÄŸerlerini analiz et:

                            AÄŸÄ±rlÄ±k: {weight:.1f}g, Kalori: {cal:.0f} kcal, Karbonhidrat: {carb:.1f}g, YaÄŸ: {fat:.1f}g, Protein: {protein:.1f}g

                            KÄ±sa ve Ã¶z bir analiz yap (150-200 kelime). YiyeceÄŸi tanÄ±mla ve temel beslenme Ã¶zelliklerini belirt.
                            """

                            response = model.generate_content([initial_prompt, image_pil])

                            # Add to chat history
                            st.session_state.chat_history.append({
                                'role': 'assistant',
                                'content': f"ğŸ“Š **Ä°lk Analiz TamamlandÄ±!**\n\n{response.text}"
                            })
                            st.session_state.last_prediction_key = prediction_key

                        except Exception as e:
                            st.error(f"Analiz hatasÄ±: {str(e)}")

            except Exception as e:
                st.error(f"FotoÄŸraf iÅŸlenirken hata: {str(e)}")

    with col2:
        st.header("ğŸ’¬ Beslenme Sohbeti")

        # Scrollable chat container
        chat_container = st.container()
        with chat_container:
            if st.session_state.chat_history:
                chat_area = st.container()
                with chat_area:
                    # Scrollable box iÃ§in CSS
                    st.markdown(
                        """
                        <style>
                        .scroll-box {
                            max-height: 400px;
                            overflow-y: auto;
                            border: 1px solid #e0e0e0;
                            border-radius: 10px;
                            padding: 15px;
                            background-color: #fafafa;
                        }
                        .user-msg {
                            background-color: #e3f2fd;
                            padding: 10px;
                            border-radius: 8px;
                            margin: 8px 0;
                            border-left: 4px solid #2196f3;
                        }
                        .assistant-msg {
                            background-color: #f1f8e9;
                            padding: 10px;
                            border-radius: 8px;
                            margin: 8px 0;
                            border-left: 4px solid #4caf50;
                        }
                        </style>
                        """,
                        unsafe_allow_html=True
                    )

                    st.markdown('<div class="scroll-box">', unsafe_allow_html=True)
                    for i, message in enumerate(st.session_state.chat_history):
                        if message['role'] == 'user':
                            st.markdown(f'<div class="user-msg"><strong>ğŸ™‹ Siz:</strong> {message["content"]}</div>',
                                        unsafe_allow_html=True)
                        else:
                            st.markdown(
                                f'<div class="assistant-msg"><strong>ğŸ¤– Asistan:</strong> {message["content"]}</div>',
                                unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.markdown(
                    """
                    <div style="height: 150px; border: 2px dashed #ccc; border-radius: 10px; 
                                display: flex; align-items: center; justify-content: center; 
                                color: #666; margin-bottom: 20px;">
                        <p>ğŸ’­ Sohbet henÃ¼z baÅŸlamadÄ±. Bir fotoÄŸraf yÃ¼kleyin ve soru sormaya baÅŸlayÄ±n!</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

    # Chat input
    if st.session_state.current_analysis and gemini_api_key:
        user_question = st.text_input(
            "Beslenme hakkÄ±nda soru sorun:",
            placeholder="Ã–rnek: Bu yiyecek kaÃ§ kiÅŸilik? Diyetime uygun mu? Hangi besinler eksik?",
            key="user_input"
        )

        col_send, col_examples = st.columns([1, 2])

        with col_send:
            if st.button("ğŸ“¨ GÃ¶nder") and user_question:
                # Add user message to history
                st.session_state.chat_history.append({
                    'role': 'user',
                    'content': user_question
                })

                # Generate response
                try:
                    with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                        model = genai.GenerativeModel('gemini-2.5-flash')

                        # Prepare context
                        analysis = st.session_state.current_analysis
                        context = f"""
                        KullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi yiyecek hakkÄ±nda ÅŸu veriler var:
                        AÄŸÄ±rlÄ±k: {analysis['weight']:.1f}g
                        Kalori: {analysis['calories']:.0f} kcal
                        Karbonhidrat: {analysis['carbs']:.1f}g
                        YaÄŸ: {analysis['fat']:.1f}g
                        Protein: {analysis['protein']:.1f}g

                        Sohbet geÃ§miÅŸi:
                        {chr(10).join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.chat_history[-5:]])}

                        KullanÄ±cÄ± sorusu: {user_question}

                        Sadece bu beslenme verilerine dayanarak cevap ver. KÄ±sa ve anlaÅŸÄ±lÄ±r ol (100-200 kelime). TÃ¼rkÃ§e cevapla.
                        """

                        # Include image for better context
                        image_pil = Image.open(analysis['image'])
                        response = model.generate_content([context, image_pil])

                        # Add response to history
                        st.session_state.chat_history.append({
                            'role': 'assistant',
                            'content': response.text
                        })

                        # Clear input and rerun
                        st.rerun()

                except Exception as e:
                    st.error(f"Cevap alÄ±nÄ±rken hata: {str(e)}")

        with col_examples:
            st.markdown("**ğŸ’¡ Ã–rnek sorular:**")
            example_questions = [
                "Bu yiyecek saÄŸlÄ±klÄ± mÄ±?",
                "KaÃ§ kiÅŸilik porsiyon?",
                "Hangi vitaminler var?",
                "Diyetime uygun mu?",
                "Kalori yoÄŸunluÄŸu nasÄ±l?"
            ]

            for idx, question in enumerate(example_questions):
                if st.button(question, key=f"example_{idx}"):
                    # Add user message to history
                    st.session_state.chat_history.append({
                        'role': 'user',
                        'content': question
                    })

                    # Generate response
                    try:
                        with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                            model = genai.GenerativeModel('gemini-2.5-flash')

                            # Prepare context
                            analysis = st.session_state.current_analysis
                            context = f"""
                            KullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi yiyecek hakkÄ±nda ÅŸu veriler var:
                            AÄŸÄ±rlÄ±k: {analysis['weight']:.1f}g
                            Kalori: {analysis['calories']:.0f} kcal
                            Karbonhidrat: {analysis['carbs']:.1f}g
                            YaÄŸ: {analysis['fat']:.1f}g
                            Protein: {analysis['protein']:.1f}g

                            KullanÄ±cÄ± sorusu: {question}

                            Sadece bu beslenme verilerine dayanarak cevap ver. KÄ±sa ve anlaÅŸÄ±lÄ±r ol (100-200 kelime). TÃ¼rkÃ§e cevapla.
                            """

                            # Include image for better context
                            image_pil = Image.open(analysis['image'])
                            response = model.generate_content([context, image_pil])

                            # Add response to history
                            st.session_state.chat_history.append({
                                'role': 'assistant',
                                'content': response.text
                            })

                            # Rerun to show new messages
                            st.rerun()

                    except Exception as e:
                        st.error(f"Cevap alÄ±nÄ±rken hata: {str(e)}")
                        st.session_state.chat_history.append({
                            'role': 'assistant',
                            'content': f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
                        })
                        st.rerun()

    elif not st.session_state.current_analysis:
        st.info("ğŸ‘† Sohbet etmek iÃ§in Ã¶nce bir fotoÄŸraf yÃ¼kleyin ve analiz edin.")
    elif not gemini_api_key:
        st.warning("âš ï¸ Sohbet iÃ§in API anahtarÄ±nÄ±zÄ± girin.")

# Visualization section (if analysis exists) - in a scrollable container
if st.session_state.current_analysis:
    st.markdown("---")
    st.header("ğŸ“ˆ GÃ¶rsel Analiz")

    # Create scrollable container for visualizations
    st.markdown(
        """
        <div style="max-height: 600px; overflow-y: auto; border: 1px solid #e0e0e0; 
                    border-radius: 10px; padding: 15px; background-color: #fafafa;">
        """,
        unsafe_allow_html=True
    )

    analysis = st.session_state.current_analysis

    col_viz1, col_viz2 = st.columns(2)

    with col_viz1:
        # Macronutrient pie chart
        import plotly.express as px
        import pandas as pd

        carb_cal = analysis['carbs'] * 4
        protein_cal = analysis['protein'] * 4
        fat_cal = analysis['fat'] * 9

        macro_df = pd.DataFrame({
            'Makrobesin': ['Karbonhidrat', 'Protein', 'YaÄŸ'],
            'Kalori': [carb_cal, protein_cal, fat_cal]
        })

        fig = px.pie(macro_df, values='Kalori', names='Makrobesin',
                     title="Kalorik DaÄŸÄ±lÄ±m")
        st.plotly_chart(fig, use_container_width=True)

    with col_viz2:
        # Nutritional density bar chart
        density_df = pd.DataFrame({
            'Besin': ['Karb.', 'Protein', 'YaÄŸ'],
            '100g baÅŸÄ±na': [
                analysis['carbs'] / analysis['weight'] * 100,
                analysis['protein'] / analysis['weight'] * 100,
                analysis['fat'] / analysis['weight'] * 100
            ]
        })

        fig2 = px.bar(density_df, x='Besin', y='100g baÅŸÄ±na',
                      title="Besin YoÄŸunluÄŸu")
        st.plotly_chart(fig2, use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
    <p>Custom SigLIP2 Regressor & Google Gemini 2.5 Flash ile gÃ¼Ã§lendirilmiÅŸtir</p>
    </div>
    """,
    unsafe_allow_html=True
)

# Instructions
with st.expander("ğŸ“‹ NasÄ±l KullanÄ±lÄ±r"):
    st.markdown("""
    **AdÄ±m adÄ±m kullanÄ±m:**

    1. **API AnahtarÄ±**: Kenar Ã§ubuÄŸuna Gemini API anahtarÄ±nÄ±zÄ± girin
    2. **FotoÄŸraf YÃ¼kle**: Sol taraftan bir yiyecek fotoÄŸrafÄ± seÃ§in
    3. **Ä°lk Analiz**: Sistem otomatik olarak beslenme analizini yapar
    4. **Soru Sor**: SaÄŸ taraftaki chatbot'a istediÄŸiniz soruyu sorun
    5. **DetaylÄ± Bilgi**: Ã–rnek sorulardan seÃ§ebilir veya kendi sorunuzu yazabilirsiniz

    **API AnahtarÄ± almak iÃ§in:**
    - [Google AI Studio](https://aistudio.google.com/app/apikey) adresine gidin
    - Yeni bir API anahtarÄ± oluÅŸturun
    """)